{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook has the optimization codes; use fitting_na_16_plotter.ipynb to make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize, stats\n",
    "import bluepyopt as bpop\n",
    "import curve_fitting as cf\n",
    "import bluepyopt.deapext.algorithms as algo\n",
    "import generalized_genSim_shorten_time as ggsd\n",
    "import vclamp_evaluator_HMM as vcl_ev\n",
    "import pickle\n",
    "import time\n",
    "from deap import tools\n",
    "import multiprocessing\n",
    "import eval_helper_na16 as eh16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just adjust these parameters, and then just run every block below to run the optimization\n",
    "\n",
    "offspring_size = 1000\n",
    "num_generations = 1000\n",
    "output_log_file_name = 'jinan_na16_new_1.txt'\n",
    "param_range_file = \"./csv_files/param_stats_wide.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bluepyopt as bpop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Vclamp_evaluator(bpop.evaluators.Evaluator):\n",
    "\n",
    "    def __init__(self, scaled):\n",
    "        \n",
    "        self.scaled = scaled\n",
    "        \n",
    "        # (val, min, max)\n",
    "        param_range_dict = eh16.read_params_range(param_range_file)\n",
    "        params_in_name = eh16.get_name_params_str()\n",
    "        params_not_in_Range_dict = ['qq', 'tq']\n",
    "        \n",
    "        eh16.set_param(eh16.get_wt_params())\n",
    "        \n",
    "        # diff is mut - wild\n",
    "        # first get baseline data points:\n",
    "        gv_slope, v_half, top, bottom = cf.calc_act_obj(\"na16\", is_HMM=False)\n",
    "        self.act_v_half = v_half\n",
    "        self.act_slope = gv_slope\n",
    "        ssi_slope, v_half, top, bottom, tau0 = cf.calc_inact_obj(\"na16\", is_HMM=False)\n",
    "        self.inact_v_half = v_half\n",
    "        self.inact_slope = ssi_slope\n",
    "        self.tau0 = eh16.find_tau0()\n",
    "        self.per_cur = eh16.find_persistent_current()\n",
    "        \n",
    "        def init_params():\n",
    "            param_list = []\n",
    "            print(\"here are the name, val, min, max of each parameter\")\n",
    "            for param in params_in_name:\n",
    "                if param not in params_not_in_Range_dict:\n",
    "                    print(param)\n",
    "                    val = param_range_dict[param][0]\n",
    "                    min_bound = param_range_dict[param][1]\n",
    "                    max_bound = param_range_dict[param][2]\n",
    "                    print(val)\n",
    "                    print((min_bound, max_bound))\n",
    "                    print(\"\")\n",
    "                    param_list.append(bpop.parameters.Parameter(param, value=val, bounds=(min_bound, max_bound)))\n",
    "            return param_list\n",
    "\n",
    "        print(\"init called\")\n",
    "        self.objectives = []\n",
    "        self.objectives.append(bpop.objectives.Objective(\"V_half_Act\"))\n",
    "        self.objectives.append(bpop.objectives.Objective(\"V_half_inact\"))\n",
    "        self.objectives.append(bpop.objectives.Objective(\"slope_Act\"))\n",
    "        self.objectives.append(bpop.objectives.Objective(\"slope_inact\"))\n",
    "        self.objectives.append(bpop.objectives.Objective(\"tau0\"))\n",
    "        self.objectives.append(bpop.objectives.Objective(\"pers_curr\"))\n",
    "        self.params = init_params()\n",
    "        \n",
    "        goal_dict = eh16.read_mutant_protocols('./csv_files/mutant_protocols.csv', 'NA16_MUT')\n",
    "        self.V_half_Act_diff_goal = goal_dict['dv_half_act']\n",
    "        self.V_half_inact_diff_goal = goal_dict['dv_half_ssi']\n",
    "        # slopes come in the 100 scale since it's a ratio, so we have to divide by 100\n",
    "        self.slope_Act_ratio_goal = goal_dict['gv_slope']/100\n",
    "        self.slope_inact_ratio_goal = goal_dict['ssi_slope']/100\n",
    "        self.tau0_ratio_goal = goal_dict['tau0']/100\n",
    "        self.per_cur_ratio_goal = goal_dict['persistent']/100\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n\\nhere are the goals:\")\n",
    "        print(self.V_half_Act_diff_goal)\n",
    "        print(self.V_half_inact_diff_goal)\n",
    "        print(self.slope_Act_ratio_goal)\n",
    "        print(self.slope_inact_ratio_goal)\n",
    "        print(self.tau0_ratio_goal)\n",
    "        print(self.per_cur_ratio_goal)\n",
    "        \n",
    "        \n",
    "    def evaluate_with_lists(self, param_values=[]):\n",
    "        \n",
    "        print(\"evaluate_with_lists is called\")\n",
    "        assert len(param_values) == len(self.params), 'no, they have to be equal...'\n",
    "        \n",
    "        currh = ggsd.Activation(channel_name = 'na16').h\n",
    "        currh.sh_na16 = param_values[0]\n",
    "        currh.tha_na16 = param_values[1]\n",
    "        currh.qa_na16 = param_values[2]\n",
    "        currh.Ra_na16 = param_values[3]\n",
    "        currh.Rb_na16 = param_values[4]\n",
    "        currh.thi1_na16 = param_values[5]\n",
    "        currh.thi2_na16 = param_values[6]\n",
    "        currh.qd_na16 = param_values[7]\n",
    "        currh.qg_na16 = param_values[8]\n",
    "        currh.mmin_na16 = param_values[9]\n",
    "        currh.hmin_na16 = param_values[10]\n",
    "        currh.q10_na16 = param_values[11]\n",
    "        currh.Rg_na16 = param_values[12]\n",
    "        currh.Rd_na16 = param_values[13]\n",
    "        currh.thinf_na16 = param_values[14]\n",
    "        currh.qinf_na16 = param_values[15]\n",
    "        currh.vhalfs_na16 = param_values[16]\n",
    "        currh.a0s_na16 = param_values[17]\n",
    "        currh.zetas_na16 = param_values[18]\n",
    "        currh.gms_na16 = param_values[19]\n",
    "        currh.smax_na16 = param_values[20]\n",
    "        currh.vvh_na16 = param_values[21]\n",
    "        currh.vvs_na16 = param_values[22]\n",
    "        currh.Ena_na16 = param_values[23]\n",
    "        \n",
    "        try:\n",
    "            gv_slope, act_v_half, act_top, act_bottom = cf.calc_act_obj(\"na16\", is_HMM=False)\n",
    "            ssi_slope, inact_v_half, inact_top, inact_bottom, tau999 = cf.calc_inact_obj(\"na16\", is_HMM=False)\n",
    "            tau0 = eh16.find_tau0()\n",
    "            per_cur = eh16.find_persistent_current()\n",
    "        except:\n",
    "            return [9999999999999999, 9999999999999999, 9999999999999999, 9999999999999999, 9999999999999999, 9999999999999999]\n",
    "        \n",
    "        V_half_Act_diff = act_v_half - self.act_v_half\n",
    "        V_half_inact_diff = inact_v_half - self.inact_v_half\n",
    "        gv_slope_ratio = gv_slope/self.act_slope\n",
    "        ssi_slope_ratio = ssi_slope/self.inact_slope\n",
    "        tau0_ratio = tau0/self.tau0\n",
    "        per_cur_ratio = per_cur/self.per_cur\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # eliminate outliers\n",
    "            act = ggsd.Activation(channel_name = 'na16')\n",
    "            act.genActivation()\n",
    "            norm_act_y_val = sorted(list(act.gnorm_vec))\n",
    "            act_fitted = eh16.get_fitted_act_conductance_arr(act.v_vec, gv_slope, act_v_half, act_top, act_bottom)\n",
    "\n",
    "            inact = ggsd.Inactivation(channel_name = 'na16')\n",
    "            inact.genInactivation()\n",
    "            norm_inact_y_val = sorted(list(inact.inorm_vec))\n",
    "            inac_fitted = eh16.get_fitted_inact_current_arr(inact.v_vec, ssi_slope, inact_v_half, inact_top, inact_bottom)\n",
    "        except:\n",
    "            return [9999999999999999, 9999999999999999, 9999999999999999, 9999999999999999, 9999999999999999, 9999999999999999]\n",
    "        \n",
    "        \n",
    "        if self.scaled:            \n",
    "            return [(V_half_Act_diff/self.V_half_Act_diff_goal - 1)**2 * 1000,\n",
    "                   (V_half_inact_diff/self.V_half_inact_diff_goal - 1)**2 * 1000,\n",
    "                   (gv_slope_ratio/self.slope_Act_ratio_goal - 1)**2 * 1000,\n",
    "                   (ssi_slope_ratio/self.slope_inact_ratio_goal - 1)**2 * 1000,\n",
    "                   (tau0_ratio/self.tau0_ratio_goal - 1)**2 * 1000,\n",
    "                   (per_cur_ratio/self.per_cur_ratio_goal - 1)**2 * 1000]\n",
    "        else:\n",
    "            return [(V_half_Act_diff - self.V_half_Act_diff_goal)**2,\n",
    "                   (V_half_inact_diff - self.V_half_inact_diff_goal)**2,\n",
    "                   (gv_slope_ratio - self.slope_Act_ratio_goal)**2,\n",
    "                   (ssi_slope_ratio - self.slope_inact_ratio_goal)**2,\n",
    "                   (tau0_ratio - self.tau0_ratio_goal)**2,\n",
    "                   (per_cur_ratio - self.per_cur_ratio_goal)**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if scaled, then we will use the scaled scoring method that assigns equal weights to each parameter. Otherwise,\n",
    "#      we will use natural weights\n",
    "evaluator = Vclamp_evaluator(scaled = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_log_file = output_log_file_name\n",
    "\n",
    "gen_counter = 0\n",
    "best_indvs = []\n",
    "cp_freq = 1\n",
    "old_update = algo._update_history_and_hof\n",
    "def my_update(halloffame, history, population):\n",
    "    global gen_counter,cp_freq\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "    \n",
    "    if halloffame:\n",
    "        best_indvs.append(halloffame[0])\n",
    "        print(halloffame[0])\n",
    "        f = open(cur_log_file, 'a')\n",
    "        f.write(str(halloffame[0]) + '\\n')\n",
    "        f.close()\n",
    "        #eh16.make_act_plots(halloffame[0])\n",
    "        #eh16.make_inact_plots(halloffame[0])\n",
    "    gen_counter = gen_counter+1\n",
    "    print(\"Current generation: \", gen_counter)\n",
    "    if gen_counter%cp_freq == 0:\n",
    "        fn = '.pkl'\n",
    "        save_logs(fn,best_indvs,population)\n",
    "\n",
    "def my_record_stats(stats, logbook, gen, population, invalid_count):\n",
    "    '''Update the statistics with the new population'''\n",
    "    record = stats.compile(population) if stats is not None else {}\n",
    "    logbook.record(gen=gen, nevals=invalid_count, **record)\n",
    "    f = open(cur_log_file, 'a')\n",
    "    f.write(str(logbook) + '\\n\\n\\n')\n",
    "    f.close()\n",
    "    print('log: \\n', logbook, '\\n')\n",
    "    output = open(\"log.pkl\", 'wb')\n",
    "    pickle.dump(logbook, output)\n",
    "    output.close()\n",
    "\n",
    "def save_logs(fn, best_indvs, hof):\n",
    "    output = open(\"indv\"+fn, 'wb')\n",
    "    pickle.dump(best_indvs, output)\n",
    "    output.close()\n",
    "    output = open(\"hof\"+fn, 'wb')\n",
    "    pickle.dump(hof, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hof = tools.HallOfFame(1, similar=np.array_equal)\n",
    "hof = tools.ParetoFront()\n",
    "algo._update_history_and_hof = my_update\n",
    "algo._record_stats = my_record_stats\n",
    "pool = multiprocessing.Pool(processes=64)\n",
    "deap_opt = bpop.optimisations.DEAPOptimisation(evaluator, offspring_size=offspring_size, hof = hof, map_function=pool.map)\n",
    "#, map_function=pool.map\n",
    "#deap_opt = bpop.optimisations.DEAPOptimisation(evaluator, offspring_size=5, hof = hof)\n",
    "cp_file = './cp.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#pop, hof, log, hst = deap_opt.run(max_ngen=5, cp_filename=cp_file)\n",
    "pop, hof, log, hst = deap_opt.run(max_ngen=num_generations, cp_filename=None)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
